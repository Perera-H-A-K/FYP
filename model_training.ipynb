{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cf938b1",
   "metadata": {},
   "source": [
    "# Notebook 2: Model Training ‚Äî Cutaneous Leishmaniasis Ulcer Classification\n",
    "\n",
    "## Purpose\n",
    "Train and validate a binary classification model for CL ulcer images using **MobileNetV2** transfer learning.\n",
    "\n",
    "- **Class 0 (Sensitive):** CL ulcers showing healing / good treatment response\n",
    "- **Class 1 (Poor):** CL ulcers showing poor treatment response\n",
    "\n",
    "## Prerequisites\n",
    "- Run `preprocessing.ipynb` first to generate `processed_data.zip`.\n",
    "- Upload `processed_data.zip` to this notebook when prompted.\n",
    "\n",
    "## Model Architecture\n",
    "- **Base:** MobileNetV2 (pretrained on ImageNet, frozen)\n",
    "- **Head:** GlobalAveragePooling ‚Üí Dropout(0.5) ‚Üí Dense(1, sigmoid)\n",
    "- **Loss:** Binary Crossentropy\n",
    "- **Optimizer:** Adam (lr=1e-4)\n",
    "\n",
    "## Data Split\n",
    "- **70% Training** / **15% Validation** (remaining 15% unused ‚Äî test data is separate)\n",
    "\n",
    "## Output\n",
    "- Trained model saved as `model.h5`\n",
    "- Training / validation accuracy and loss plots\n",
    "\n",
    "---\n",
    "**Target test accuracy: ~0.6** (clinically realistic for small CL datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00a1018",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ed6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Google Colab file upload utility\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running in Google Colab. Manual upload will be skipped.\")\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e300020d",
   "metadata": {},
   "source": [
    "## 2. Upload Preprocessed Data (Manual Upload)\n",
    "\n",
    "Upload the `processed_data.zip` file generated by **Notebook 1** (`preprocessing.ipynb`).  \n",
    "This ZIP should contain:\n",
    "```\n",
    "processed_data/\n",
    "  ‚îú‚îÄ‚îÄ sensitive/   ‚Üê Preprocessed healing CL ulcer images\n",
    "  ‚îî‚îÄ‚îÄ poor/        ‚Üê Preprocessed poor-response CL ulcer images\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# UPLOAD PREPROCESSED DATA\n",
    "# ============================================================\n",
    "\n",
    "DATA_DIR = 'processed_data'\n",
    "CLASSES = ['sensitive', 'poor']\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"=\"*50)\n",
    "    print(\"  STEP: Upload processed_data.zip\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Select the processed_data.zip from Notebook 1.\\n\")\n",
    "\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    for filename in uploaded.keys():\n",
    "        if filename.endswith('.zip'):\n",
    "            print(f\"\\nExtracting '{filename}'...\")\n",
    "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "                zip_ref.extractall('.')\n",
    "            print(f\"Extraction complete.\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  '{filename}' is not a ZIP file.\")\n",
    "else:\n",
    "    print(\"Not in Colab. Ensure 'processed_data/' folder exists.\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# AUTO-DETECT DIRECTORY (handles different ZIP layouts)\n",
    "# --------------------------------------------------\n",
    "def find_data_dir(expected_name, required_subdirs):\n",
    "    \"\"\"Find directory containing required subdirectories after extraction.\"\"\"\n",
    "    # Case 1: Expected directory exists\n",
    "    if os.path.isdir(expected_name):\n",
    "        if all(os.path.isdir(os.path.join(expected_name, s)) for s in required_subdirs):\n",
    "            return expected_name\n",
    "\n",
    "    # Case 2: Subdirs exist at root\n",
    "    if all(os.path.isdir(s) for s in required_subdirs):\n",
    "        os.makedirs(expected_name, exist_ok=True)\n",
    "        for s in required_subdirs:\n",
    "            dest = os.path.join(expected_name, s)\n",
    "            if not os.path.exists(dest):\n",
    "                shutil.move(s, dest)\n",
    "        return expected_name\n",
    "\n",
    "    # Case 3: Search in extracted content\n",
    "    for root, dirs, _ in os.walk('.'):\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__MACOSX']\n",
    "        if all(s in dirs for s in required_subdirs) and root != '.':\n",
    "            return root\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find directory with subdirectories {required_subdirs}.\\n\"\n",
    "        f\"Check your ZIP structure.\"\n",
    "    )\n",
    "\n",
    "DATA_DIR = find_data_dir(DATA_DIR, CLASSES)\n",
    "print(f\"\\n‚úÖ Using data directory: '{DATA_DIR}/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e16423d",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Data\n",
    "\n",
    "Load preprocessed CL ulcer images, assign binary labels, and prepare for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b9e0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LOAD PREPROCESSED IMAGES AND ASSIGN LABELS\n",
    "# Class 0: sensitive (healing CL ulcers)\n",
    "# Class 1: poor (poor-response CL ulcers)\n",
    "# ============================================================\n",
    "\n",
    "IMG_SIZE = 224\n",
    "VALID_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}\n",
    "IGNORE_FILES = {'.ds_store', 'thumbs.db', 'desktop.ini'}\n",
    "\n",
    "# Class mapping\n",
    "CLASS_MAP = {\n",
    "    'sensitive': 0,  # Healing / good treatment response\n",
    "    'poor': 1        # Poor treatment response\n",
    "}\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for class_name, label in CLASS_MAP.items():\n",
    "    class_dir = os.path.join(DATA_DIR, class_name)\n",
    "\n",
    "    if not os.path.isdir(class_dir):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Directory '{class_dir}' not found.\\n\"\n",
    "            f\"Ensure {DATA_DIR}/ has 'sensitive/' and 'poor/' subdirectories.\"\n",
    "        )\n",
    "\n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(class_dir)\n",
    "        if os.path.splitext(f)[1].lower() in VALID_EXTENSIONS\n",
    "        and not f.startswith('.')\n",
    "        and f.lower() not in IGNORE_FILES\n",
    "    ])\n",
    "\n",
    "    print(f\"Loading class '{class_name}' (label={label}): {len(image_files)} images\")\n",
    "\n",
    "    for fname in image_files:\n",
    "        img_path = os.path.join(class_dir, fname)\n",
    "\n",
    "        # Load as grayscale (preprocessed L-channel images are single-channel)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"  ‚ö†Ô∏è  Skipping unreadable file: {fname}\")\n",
    "            continue\n",
    "\n",
    "        # Ensure correct dimensions\n",
    "        if img.shape[0] != IMG_SIZE or img.shape[1] != IMG_SIZE:\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "        # Normalize to [0, 1]\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "\n",
    "        images.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "if len(images) == 0:\n",
    "    raise ValueError(\"No images were loaded! Check your processed_data/ folder.\")\n",
    "\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "print(f\"\\nTotal loaded: {len(X)} images\")\n",
    "print(f\"  Sensitive (label 0): {np.sum(y == 0)}\")\n",
    "print(f\"  Poor (label 1):      {np.sum(y == 1)}\")\n",
    "print(f\"  Image shape: {X[0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREPARE DATA FOR MOBILENETV2\n",
    "# MobileNetV2 expects 3-channel (RGB) input.\n",
    "# We replicate the grayscale L-channel across 3 channels.\n",
    "# This preserves the CLAHE-enhanced texture information\n",
    "# while matching the pretrained model's expected input format.\n",
    "# ============================================================\n",
    "\n",
    "# Expand: (N, 224, 224) ‚Üí (N, 224, 224, 1) ‚Üí (N, 224, 224, 3)\n",
    "X = np.expand_dims(X, axis=-1)\n",
    "X = np.repeat(X, 3, axis=-1)\n",
    "\n",
    "print(f\"Model input shape: {X.shape}\")\n",
    "print(f\"Labels shape:      {y.shape}\")\n",
    "print(f\"Pixel range:       [{X.min():.4f}, {X.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3054f1c8",
   "metadata": {},
   "source": [
    "## 4. Train / Validation Split\n",
    "\n",
    "Split data into **70% training** and **15% validation**.\n",
    "\n",
    "The remaining 15% is reserved conceptually for testing, which is handled separately in Notebook 3 with its own unseen test data upload. To maximize usage of every available image, we perform a direct 70/15 ratio split on all loaded data:\n",
    "- Training:   82.4% of loaded data  (= 70 / (70+15))\n",
    "- Validation: 17.6% of loaded data  (= 15 / (70+15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c4696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN / VALIDATION SPLIT\n",
    "# 70% train : 15% validation ratio\n",
    "# Split ratio: val_size = 15/(70+15) ‚âà 0.176\n",
    "# Stratified to maintain class balance\n",
    "# ============================================================\n",
    "\n",
    "VAL_RATIO = 15.0 / (70.0 + 15.0)  # ‚âà 0.176\n",
    "\n",
    "# Minimum samples check: stratified split requires >=2 per class in each set\n",
    "min_class_count = min(np.sum(y == 0), np.sum(y == 1))\n",
    "min_needed = max(2, int(np.ceil(1.0 / VAL_RATIO)))  # Need enough for at least 1 val sample\n",
    "\n",
    "if min_class_count < 2:\n",
    "    raise ValueError(\n",
    "        f\"Each class must have at least 2 images. \"\n",
    "        f\"Found: sensitive={np.sum(y == 0)}, poor={np.sum(y == 1)}\"\n",
    "    )\n",
    "\n",
    "# Use stratified split if enough samples, otherwise simple split\n",
    "use_stratify = min_class_count >= 4  # Need >=4 per class for reliable stratification\n",
    "\n",
    "try:\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y,\n",
    "        test_size=VAL_RATIO,\n",
    "        random_state=SEED,\n",
    "        stratify=y if use_stratify else None\n",
    "    )\n",
    "except ValueError as e:\n",
    "    # Fallback: if stratified split fails due to tiny dataset, use non-stratified\n",
    "    print(f\"  ‚ö†Ô∏è  Stratified split failed ({e}). Using non-stratified split.\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y,\n",
    "        test_size=VAL_RATIO,\n",
    "        random_state=SEED,\n",
    "        stratify=None\n",
    "    )\n",
    "\n",
    "print(f\"Data split summary:\")\n",
    "print(f\"  Training:   {len(X_train)} images ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"    Sensitive: {np.sum(y_train == 0)}, Poor: {np.sum(y_train == 1)}\")\n",
    "print(f\"  Validation: {len(X_val)} images ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"    Sensitive: {np.sum(y_val == 0)}, Poor: {np.sum(y_val == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e941df",
   "metadata": {},
   "source": [
    "## 5. Build Model ‚Äî MobileNetV2 Transfer Learning\n",
    "\n",
    "### Architecture\n",
    "| Layer | Description |\n",
    "|-------|-------------|\n",
    "| MobileNetV2 | Pretrained on ImageNet, **frozen** (no fine-tuning) |\n",
    "| GlobalAveragePooling2D | Reduces spatial dims to feature vector |\n",
    "| Dropout(0.5) | Regularization for small dataset |\n",
    "| Dense(1, sigmoid) | Binary output: P(poor-response) |\n",
    "\n",
    "### Why freeze the base?\n",
    "With a small medical dataset, fine-tuning all layers would cause **severe overfitting**.\n",
    "The frozen MobileNetV2 base provides robust feature extraction (edges, textures, shapes)\n",
    "learned from ImageNet that transfer well to ulcer morphology analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b7b604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BUILD MODEL: MobileNetV2 + Classification Head\n",
    "# ============================================================\n",
    "\n",
    "def build_model(input_shape=(224, 224, 3)):\n",
    "    \"\"\"\n",
    "    Binary classifier using MobileNetV2 transfer learning.\n",
    "\n",
    "    Architecture:\n",
    "        MobileNetV2 (frozen) ‚Üí GlobalAvgPool ‚Üí Dropout(0.5) ‚Üí Dense(1, sigmoid)\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model.\n",
    "    \"\"\"\n",
    "    # Load pretrained MobileNetV2 (without ImageNet classification head)\n",
    "    base_model = MobileNetV2(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "\n",
    "    # Freeze all base layers ‚Äî prevent weight updates\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Build classification head\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.5),             # Regularization for small dataset\n",
    "        layers.Dense(1, activation='sigmoid')  # P(class=poor)\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3c4fcd",
   "metadata": {},
   "source": [
    "## 6. Train the Model\n",
    "\n",
    "- **Epochs:** 15 (with early stopping)\n",
    "- **Batch size:** 16\n",
    "- **Class weights:** Computed to handle class imbalance\n",
    "- **Early stopping:** patience=5 on validation loss, restores best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0f7f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAINING CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# --- Class weights ---\n",
    "# Medical datasets are often imbalanced.\n",
    "# Class weights penalize misclassification of minority class more heavily.\n",
    "unique_classes = np.unique(y_train)\n",
    "if len(unique_classes) >= 2:\n",
    "    cw_array = compute_class_weight('balanced', classes=unique_classes, y=y_train)\n",
    "    class_weights = {int(c): w for c, w in zip(unique_classes, cw_array)}\n",
    "else:\n",
    "    # Only one class in training set ‚Äî no weighting possible\n",
    "    print(\"‚ö†Ô∏è  WARNING: Only one class in training data. Class weighting disabled.\")\n",
    "    class_weights = None\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")\n",
    "\n",
    "# --- Early Stopping ---\n",
    "# Stops training when validation loss stops improving.\n",
    "# Restores best weights to avoid using an overfit checkpoint.\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Epochs:      {EPOCHS}\")\n",
    "print(f\"  Batch size:  {BATCH_SIZE}\")\n",
    "print(f\"  Train size:  {len(X_train)}\")\n",
    "print(f\"  Val size:    {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd515a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN THE MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(\"Starting model training...\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3d64fd",
   "metadata": {},
   "source": [
    "## 7. Training Results\n",
    "\n",
    "Display final metrics and plot training curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c3668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DISPLAY TRAINING METRICS\n",
    "# ============================================================\n",
    "\n",
    "final_epoch = len(history.history['accuracy'])\n",
    "train_acc = history.history['accuracy'][-1]\n",
    "val_acc = history.history['val_accuracy'][-1]\n",
    "train_loss = history.history['loss'][-1]\n",
    "val_loss = history.history['val_loss'][-1]\n",
    "\n",
    "print(f\"Training completed after {final_epoch} epoch(s)\")\n",
    "print(f\"{'='*45}\")\n",
    "print(f\"  Final Training Accuracy:    {train_acc:.4f}\")\n",
    "print(f\"  Final Validation Accuracy:  {val_acc:.4f}\")\n",
    "print(f\"  Final Training Loss:        {train_loss:.4f}\")\n",
    "print(f\"  Final Validation Loss:      {val_loss:.4f}\")\n",
    "print(f\"{'='*45}\")\n",
    "\n",
    "best_val_acc = max(history.history['val_accuracy'])\n",
    "best_epoch = int(np.argmax(history.history['val_accuracy'])) + 1\n",
    "print(f\"  Best Validation Accuracy:   {best_val_acc:.4f} (Epoch {best_epoch})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PLOT: Accuracy and Loss vs Epoch\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs_range = range(1, final_epoch + 1)\n",
    "\n",
    "# --- Accuracy Plot ---\n",
    "axes[0].plot(epochs_range, history.history['accuracy'],\n",
    "             'b-o', label='Training Accuracy', linewidth=2, markersize=5)\n",
    "axes[0].plot(epochs_range, history.history['val_accuracy'],\n",
    "             'r-s', label='Validation Accuracy', linewidth=2, markersize=5)\n",
    "axes[0].set_title('Accuracy vs Epoch', fontsize=13, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=11)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=11)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_xticks(list(epochs_range))\n",
    "\n",
    "# --- Loss Plot ---\n",
    "axes[1].plot(epochs_range, history.history['loss'],\n",
    "             'b-o', label='Training Loss', linewidth=2, markersize=5)\n",
    "axes[1].plot(epochs_range, history.history['val_loss'],\n",
    "             'r-s', label='Validation Loss', linewidth=2, markersize=5)\n",
    "axes[1].set_title('Loss vs Epoch', fontsize=13, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=11)\n",
    "axes[1].set_ylabel('Loss', fontsize=11)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_xticks(list(epochs_range))\n",
    "\n",
    "plt.suptitle('CL Ulcer Classification ‚Äî MobileNetV2 Training History',\n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b47e4",
   "metadata": {},
   "source": [
    "## 8. Save Trained Model\n",
    "\n",
    "Save as `model.h5` for use in **Notebook 3** (`model_testing.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ba44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SAVE TRAINED MODEL\n",
    "# ============================================================\n",
    "\n",
    "MODEL_PATH = 'model.h5'\n",
    "\n",
    "model.save(MODEL_PATH)\n",
    "print(f\"‚úÖ Model saved as: {MODEL_PATH}\")\n",
    "\n",
    "model_size_mb = os.path.getsize(MODEL_PATH) / (1024 * 1024)\n",
    "print(f\"   File size: {model_size_mb:.2f} MB\")\n",
    "\n",
    "# Download\n",
    "if IN_COLAB:\n",
    "    files.download(MODEL_PATH)\n",
    "    print(\"\\nüì• Download started.\")\n",
    "else:\n",
    "    print(f\"\\nModel saved in working directory.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"  NOTEBOOK 2 COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nNext step:\")\n",
    "print(\"  1. Open model_testing.ipynb\")\n",
    "print(\"  2. Upload model.h5 when prompted\")\n",
    "print(\"  3. Upload your test dataset ZIP when prompted\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
