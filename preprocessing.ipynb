{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0199b7",
   "metadata": {},
   "source": [
    "# Notebook 1: Preprocessing of Cutaneous Leishmaniasis Ulcer Images\n",
    "\n",
    "## Purpose\n",
    "This notebook preprocesses **cutaneous leishmaniasis (CL) ulcer images** for a binary classification task:\n",
    "- **Class 0 (Sensitive):** CL ulcers showing healing / good treatment response\n",
    "- **Class 1 (Poor):** CL ulcers showing poor treatment response\n",
    "\n",
    "## Clinical Data Constraint\n",
    "‚ö†Ô∏è **The dataset MUST contain ONLY cutaneous leishmaniasis ulcer wounds.**  \n",
    "Do NOT include: non-disease wounds, traumatic cuts, burns, diabetic ulcers, pressure sores, healthy skin, or any non-CL skin lesions.\n",
    "\n",
    "## Preprocessing Pipeline\n",
    "1. Resize images to 224√ó224 pixels\n",
    "2. Convert RGB ‚Üí CIE LAB color space\n",
    "3. Extract L (luminosity) channel\n",
    "4. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "5. Apply median filtering for noise reduction\n",
    "6. Normalize pixel values to [0, 1]\n",
    "\n",
    "## Output\n",
    "Preprocessed images saved to `processed_data/sensitive/` and `processed_data/poor/`.\n",
    "\n",
    "---\n",
    "**‚ö†Ô∏è This notebook does NOT perform any model training or data splitting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca9b86",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "# Google Colab file upload utility\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Not running in Google Colab. Manual upload will be skipped.\")\n",
    "\n",
    "print(\"All libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3601748",
   "metadata": {},
   "source": [
    "## 2. Upload Dataset (Manual Upload)\n",
    "\n",
    "### Instructions\n",
    "1. Prepare your CL ulcer images in TWO folders: `sensitive/` and `poor/`\n",
    "2. Place both folders inside a parent folder called `dataset/`\n",
    "3. Compress `dataset/` into a **ZIP file** (e.g., `dataset.zip`)\n",
    "4. Run the cell below ‚Äî a file-upload dialog will appear\n",
    "5. Select and upload your `dataset.zip`\n",
    "\n",
    "### Expected ZIP Structure\n",
    "```\n",
    "dataset.zip\n",
    "  ‚îî‚îÄ‚îÄ dataset/\n",
    "        ‚îú‚îÄ‚îÄ sensitive/    ‚Üê CL ulcers showing healing / good response\n",
    "        ‚îÇ     ‚îú‚îÄ‚îÄ img001.jpg\n",
    "        ‚îÇ     ‚îú‚îÄ‚îÄ img002.png\n",
    "        ‚îÇ     ‚îî‚îÄ‚îÄ ...\n",
    "        ‚îî‚îÄ‚îÄ poor/         ‚Üê CL ulcers showing poor treatment response\n",
    "              ‚îú‚îÄ‚îÄ img001.jpg\n",
    "              ‚îú‚îÄ‚îÄ img002.png\n",
    "              ‚îî‚îÄ‚îÄ ...\n",
    "```\n",
    "\n",
    "**‚ö†Ô∏è Clinical Reminder:**  \n",
    "Ensure ALL images are **cutaneous leishmaniasis ulcer wounds ONLY**.  \n",
    "Do NOT include non-CL wounds, healthy skin, burns, diabetic ulcers, or any other lesion type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATASET UPLOAD\n",
    "# Upload your dataset as a ZIP file\n",
    "# ============================================================\n",
    "\n",
    "DATASET_DIR = 'dataset'\n",
    "CLASSES = ['sensitive', 'poor']\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"=\"*50)\n",
    "    print(\"  STEP: Upload your dataset ZIP file\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Please select your ZIP file containing:\")\n",
    "    print(\"  dataset/sensitive/  and  dataset/poor/\\n\")\n",
    "\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    # Extract the uploaded zip file\n",
    "    for filename in uploaded.keys():\n",
    "        if filename.endswith('.zip'):\n",
    "            print(f\"\\nExtracting '{filename}'...\")\n",
    "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "                zip_ref.extractall('.')\n",
    "            print(f\"Extraction complete.\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: '{filename}' is not a ZIP file. Please upload a .zip file.\")\n",
    "else:\n",
    "    print(\"Not in Colab. Ensure 'dataset/' folder exists in the working directory.\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# AUTO-DETECT DATASET DIRECTORY\n",
    "# Handles different ZIP structures:\n",
    "#   Case 1: dataset/sensitive/ + dataset/poor/  (expected)\n",
    "#   Case 2: sensitive/ + poor/ at root           (no parent)\n",
    "#   Case 3: some_folder/sensitive/ + poor/       (different name)\n",
    "# --------------------------------------------------\n",
    "\n",
    "def find_dataset_dir(expected_name, required_subdirs):\n",
    "    \"\"\"\n",
    "    Auto-detect the dataset directory after ZIP extraction.\n",
    "    Returns the path to the directory containing the required subdirectories.\n",
    "    \"\"\"\n",
    "    # Case 1: Expected directory exists with correct subdirs\n",
    "    if os.path.isdir(expected_name):\n",
    "        if all(os.path.isdir(os.path.join(expected_name, s)) for s in required_subdirs):\n",
    "            return expected_name\n",
    "\n",
    "    # Case 2: Subdirs exist directly in working directory\n",
    "    if all(os.path.isdir(s) for s in required_subdirs):\n",
    "        os.makedirs(expected_name, exist_ok=True)\n",
    "        for s in required_subdirs:\n",
    "            dest = os.path.join(expected_name, s)\n",
    "            if not os.path.exists(dest):\n",
    "                shutil.move(s, dest)\n",
    "        print(f\"  Detected subdirs at root level ‚Äî moved into '{expected_name}/'\")\n",
    "        return expected_name\n",
    "\n",
    "    # Case 3: Search for any directory containing both required subdirs\n",
    "    for root, dirs, _ in os.walk('.'):\n",
    "        # Skip hidden/system directories\n",
    "        dirs[:] = [d for d in dirs if not d.startswith('.') and d != '__MACOSX']\n",
    "        if all(s in dirs for s in required_subdirs):\n",
    "            found_path = root\n",
    "            if found_path != '.':\n",
    "                print(f\"  Auto-detected dataset directory: '{found_path}'\")\n",
    "                return found_path\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        f\"Could not find a directory containing {required_subdirs}.\\n\"\n",
    "        f\"Please ensure your ZIP file contains a folder with \"\n",
    "        f\"'{required_subdirs[0]}/' and '{required_subdirs[1]}/' subdirectories.\"\n",
    "    )\n",
    "\n",
    "DATASET_DIR = find_dataset_dir(DATASET_DIR, CLASSES)\n",
    "print(f\"\\n‚úÖ Using dataset directory: '{DATASET_DIR}/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdbea86",
   "metadata": {},
   "source": [
    "## 3. Validate Dataset Structure\n",
    "\n",
    "Verify folder structure, count images, and warn about any non-image files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATASET VALIDATION\n",
    "# ============================================================\n",
    "\n",
    "VALID_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff'}\n",
    "\n",
    "# Files to ignore (OS-generated junk files)\n",
    "IGNORE_FILES = {'.ds_store', 'thumbs.db', 'desktop.ini', '.gitkeep'}\n",
    "\n",
    "\n",
    "def is_valid_image_file(filename):\n",
    "    \"\"\"Check if a filename is a valid image (not a hidden/system file).\"\"\"\n",
    "    name_lower = filename.lower()\n",
    "    # Skip hidden files, system files, and __MACOSX junk\n",
    "    if filename.startswith('.') or name_lower in IGNORE_FILES:\n",
    "        return False\n",
    "    ext = os.path.splitext(filename)[1].lower()\n",
    "    return ext in VALID_EXTENSIONS\n",
    "\n",
    "\n",
    "def validate_dataset(dataset_dir, classes):\n",
    "    \"\"\"\n",
    "    Validate the dataset directory structure and count images.\n",
    "\n",
    "    Clinical Note: This checks file types only. It CANNOT verify\n",
    "    clinical content ‚Äî the user MUST ensure images are CL ulcers ONLY.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(dataset_dir):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset directory '{dataset_dir}' not found. \"\n",
    "            f\"Please upload and extract the dataset first.\"\n",
    "        )\n",
    "\n",
    "    total_images = 0\n",
    "    class_counts = {}\n",
    "\n",
    "    for cls in classes:\n",
    "        cls_path = os.path.join(dataset_dir, cls)\n",
    "        if not os.path.isdir(cls_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"Class directory '{cls_path}' not found.\\n\"\n",
    "                f\"Expected subdirectories: {classes}\"\n",
    "            )\n",
    "\n",
    "        # Count valid image files\n",
    "        image_files = [f for f in os.listdir(cls_path) if is_valid_image_file(f)]\n",
    "        count = len(image_files)\n",
    "        total_images += count\n",
    "        class_counts[cls] = count\n",
    "\n",
    "        # Warn about non-image files (excluding known junk)\n",
    "        all_files = os.listdir(cls_path)\n",
    "        skipped = [f for f in all_files if not is_valid_image_file(f) and f.lower() not in IGNORE_FILES and not f.startswith('.')]\n",
    "        if skipped:\n",
    "            print(f\"  ‚ö†Ô∏è  Non-image files in '{cls}/': {skipped[:5]}{'...' if len(skipped) > 5 else ''}\")\n",
    "\n",
    "        print(f\"  Class '{cls}': {count} valid image(s)\")\n",
    "\n",
    "    if total_images == 0:\n",
    "        raise ValueError(\n",
    "            \"No valid images found in the dataset!\\n\"\n",
    "            \"Supported formats: .jpg, .jpeg, .png, .bmp, .tif, .tiff\"\n",
    "        )\n",
    "\n",
    "    # Warn about severe class imbalance\n",
    "    counts = list(class_counts.values())\n",
    "    if min(counts) > 0 and max(counts) / min(counts) > 5:\n",
    "        print(f\"\\n  ‚ö†Ô∏è  WARNING: Severe class imbalance detected!\")\n",
    "        print(f\"     This may affect model training performance.\")\n",
    "\n",
    "    print(f\"\\n  Total valid images: {total_images}\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"‚ö†Ô∏è  CLINICAL REMINDER:\")\n",
    "    print(\"  Ensure ALL images are cutaneous leishmaniasis\")\n",
    "    print(\"  ulcer wounds ONLY. Do NOT include:\")\n",
    "    print(\"  - Non-CL wounds, burns, diabetic ulcers\")\n",
    "    print(\"  - Pressure sores, healthy skin\")\n",
    "    print(\"  - Any non-leishmaniasis skin lesions\")\n",
    "    print(\"=\"*50)\n",
    "    return True\n",
    "\n",
    "\n",
    "print(\"Validating dataset structure...\\n\")\n",
    "validate_dataset(DATASET_DIR, CLASSES)\n",
    "print(\"\\n‚úÖ Dataset validation passed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a61da",
   "metadata": {},
   "source": [
    "## 4. Define Preprocessing Functions\n",
    "\n",
    "### Preprocessing Pipeline (Medical Image Processing)\n",
    "\n",
    "Each CL ulcer image undergoes the following steps:\n",
    "\n",
    "| Step | Operation | Medical Rationale |\n",
    "|------|-----------|-------------------|\n",
    "| 1 | Resize to 224√ó224 | Standard deep learning input size |\n",
    "| 2 | RGB ‚Üí CIE LAB | Separates luminosity from color information |\n",
    "| 3 | Extract L channel | Captures ulcer structure independent of skin tone |\n",
    "| 4 | CLAHE | Enhances ulcer borders and tissue texture contrast |\n",
    "| 5 | Median filter | Removes noise while preserving ulcer edges |\n",
    "| 6 | Normalize [0,1] | Required for stable neural network training |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREPROCESSING FUNCTIONS\n",
    "# Medical image preprocessing pipeline for CL ulcer images\n",
    "# ============================================================\n",
    "\n",
    "# Target image dimensions (standard for deep learning models)\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# CLAHE parameters\n",
    "# clipLimit=2.0: controls contrast amplification ‚Äî good default for medical images\n",
    "# tileGridSize=(8,8): divides image into 8x8 tiles for local equalization\n",
    "CLAHE_CLIP_LIMIT = 2.0\n",
    "CLAHE_TILE_SIZE = (8, 8)\n",
    "\n",
    "# Median filter kernel size (must be odd; 5 balances noise removal + edge preservation)\n",
    "MEDIAN_KERNEL_SIZE = 5\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    Apply the full preprocessing pipeline to a single CL ulcer image.\n",
    "\n",
    "    Pipeline:\n",
    "      1. Load and resize to 224x224\n",
    "      2. Convert RGB ‚Üí CIE LAB color space\n",
    "      3. Extract L (luminosity) channel\n",
    "      4. Apply CLAHE for contrast enhancement\n",
    "      5. Apply median filtering for noise reduction\n",
    "      6. Normalize pixel values to [0, 1]\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (processed_image, original_rgb) or (None, None) on failure.\n",
    "            processed_image: numpy.ndarray, shape (224,224), float32, [0,1]\n",
    "            original_rgb: numpy.ndarray, shape (224,224,3), uint8, [0,255]\n",
    "    \"\"\"\n",
    "    # Step 1: Load image (OpenCV loads as BGR)\n",
    "    img_bgr = cv2.imread(image_path)\n",
    "\n",
    "    if img_bgr is None:\n",
    "        print(f\"  ‚ö†Ô∏è  Could not load image: {os.path.basename(image_path)}\")\n",
    "        print(f\"     Skipping ‚Äî verify it is a valid image file.\")\n",
    "        return None, None\n",
    "\n",
    "    # Resize to 224x224\n",
    "    img_bgr = cv2.resize(img_bgr, IMG_SIZE, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Keep RGB copy for visualization\n",
    "    original_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Step 2: Convert BGR ‚Üí CIE LAB color space\n",
    "    # LAB separates lightness (L) from color (A, B).\n",
    "    # This is ideal for medical imaging where intensity patterns\n",
    "    # carry clinical information about ulcer healing status.\n",
    "    img_lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Step 3: Extract L (luminosity) channel\n",
    "    # The L channel captures structural/textural detail of the ulcer\n",
    "    # independent of color variation due to lighting or skin tone.\n",
    "    l_channel = img_lab[:, :, 0]\n",
    "\n",
    "    # Step 4: Apply CLAHE\n",
    "    # Enhances local contrast ‚Äî makes ulcer borders and tissue\n",
    "    # texture differences more visible for the classifier.\n",
    "    clahe = cv2.createCLAHE(clipLimit=CLAHE_CLIP_LIMIT, tileGridSize=CLAHE_TILE_SIZE)\n",
    "    l_clahe = clahe.apply(l_channel)\n",
    "\n",
    "    # Step 5: Median filtering\n",
    "    # Removes salt-and-pepper noise from camera artifacts\n",
    "    # while preserving ulcer boundary edges.\n",
    "    l_filtered = cv2.medianBlur(l_clahe, MEDIAN_KERNEL_SIZE)\n",
    "\n",
    "    # Step 6: Normalize to [0, 1] range\n",
    "    # Required for stable neural network training.\n",
    "    processed = l_filtered.astype(np.float32) / 255.0\n",
    "\n",
    "    return processed, original_rgb\n",
    "\n",
    "\n",
    "def save_processed_image(image, save_path):\n",
    "    \"\"\"\n",
    "    Save a preprocessed image (float32, [0,1]) as a PNG file.\n",
    "    Converts back to uint8 [0,255] for saving.\n",
    "    \"\"\"\n",
    "    img_uint8 = (image * 255.0).astype(np.uint8)\n",
    "    success = cv2.imwrite(save_path, img_uint8)\n",
    "    if not success:\n",
    "        print(f\"  ‚ö†Ô∏è  Failed to save: {save_path}\")\n",
    "    return success\n",
    "\n",
    "\n",
    "print(\"‚úÖ Preprocessing functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c354fd",
   "metadata": {},
   "source": [
    "## 5. Run Preprocessing Pipeline\n",
    "\n",
    "Process all CL ulcer images and save to `processed_data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0934ea86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RUN PREPROCESSING ON FULL DATASET\n",
    "# ============================================================\n",
    "\n",
    "OUTPUT_DIR = 'processed_data'\n",
    "\n",
    "# Store first sample for visualization\n",
    "sample_original = None\n",
    "sample_processed = None\n",
    "sample_name = None\n",
    "\n",
    "total_success = 0\n",
    "total_fail = 0\n",
    "\n",
    "for cls in CLASSES:\n",
    "    input_dir = os.path.join(DATASET_DIR, cls)\n",
    "    output_dir = os.path.join(OUTPUT_DIR, cls)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get valid image files (skip hidden/system files)\n",
    "    image_files = sorted([f for f in os.listdir(input_dir) if is_valid_image_file(f)])\n",
    "\n",
    "    print(f\"\\nProcessing class '{cls}': {len(image_files)} images...\")\n",
    "\n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "\n",
    "    for i, fname in enumerate(image_files):\n",
    "        input_path = os.path.join(input_dir, fname)\n",
    "\n",
    "        # Apply preprocessing\n",
    "        processed, original = preprocess_image(input_path)\n",
    "\n",
    "        if processed is None:\n",
    "            fail_count += 1\n",
    "            continue\n",
    "\n",
    "        # Save as PNG\n",
    "        output_fname = os.path.splitext(fname)[0] + '.png'\n",
    "        output_path = os.path.join(output_dir, output_fname)\n",
    "        save_processed_image(processed, output_path)\n",
    "        success_count += 1\n",
    "\n",
    "        # Store first sample for visualization\n",
    "        if sample_original is None:\n",
    "            sample_original = original\n",
    "            sample_processed = processed\n",
    "            sample_name = fname\n",
    "\n",
    "        # Progress every 10 images\n",
    "        if (i + 1) % 10 == 0 or (i + 1) == len(image_files):\n",
    "            print(f\"  [{i + 1}/{len(image_files)}] processed\")\n",
    "\n",
    "    total_success += success_count\n",
    "    total_fail += fail_count\n",
    "    print(f\"  ‚úÖ '{cls}': {success_count} succeeded, {fail_count} failed\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"  PREPROCESSING COMPLETE\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"  Total processed: {total_success}\")\n",
    "print(f\"  Total failed:    {total_fail}\")\n",
    "print(f\"  Output folder:   '{OUTPUT_DIR}/'\")\n",
    "for cls in CLASSES:\n",
    "    out_dir = os.path.join(OUTPUT_DIR, cls)\n",
    "    count = len([f for f in os.listdir(out_dir) if is_valid_image_file(f)])\n",
    "    print(f\"    {cls}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ae9ed3",
   "metadata": {},
   "source": [
    "## 6. Visualization: Original vs Preprocessed\n",
    "\n",
    "Display one CL ulcer image before and after the preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa3918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZATION: Side-by-side comparison\n",
    "# ============================================================\n",
    "\n",
    "if sample_original is not None and sample_processed is not None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Original RGB image\n",
    "    axes[0].imshow(sample_original)\n",
    "    axes[0].set_title(f'Original CL Ulcer Image\\n({sample_name})', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Preprocessed image (L channel, CLAHE, median, normalized)\n",
    "    axes[1].imshow(sample_processed, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1].set_title('Preprocessed\\n(LAB-L + CLAHE + Median + Normalized)', fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    plt.suptitle('Cutaneous Leishmaniasis Ulcer ‚Äî Preprocessing Result',\n",
    "                 fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Original shape:      {sample_original.shape}\")\n",
    "    print(f\"Preprocessed shape:  {sample_processed.shape}\")\n",
    "    print(f\"Pixel value range:   [{sample_processed.min():.4f}, {sample_processed.max():.4f}]\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No images were successfully processed. Please check your dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0126f",
   "metadata": {},
   "source": [
    "## 7. Download Processed Data\n",
    "\n",
    "Zip and download the `processed_data/` folder.  \n",
    "You will need this file in **Notebook 2** (`model_training.ipynb`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df315b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ZIP AND DOWNLOAD processed_data/\n",
    "# ============================================================\n",
    "\n",
    "ZIP_NAME = 'processed_data'\n",
    "\n",
    "# Create zip\n",
    "shutil.make_archive(ZIP_NAME, 'zip', '.', 'processed_data')\n",
    "zip_path = ZIP_NAME + '.zip'\n",
    "zip_size_mb = os.path.getsize(zip_path) / (1024 * 1024)\n",
    "print(f\"Created: {zip_path} ({zip_size_mb:.2f} MB)\")\n",
    "\n",
    "# Download in Colab\n",
    "if IN_COLAB:\n",
    "    files.download(zip_path)\n",
    "    print(\"\\nüì• Download started.\")\n",
    "else:\n",
    "    print(f\"\\nFile saved as '{zip_path}' in the working directory.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"  NOTEBOOK 1 COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nNext step:\")\n",
    "print(\"  1. Open model_training.ipynb\")\n",
    "print(\"  2. Upload processed_data.zip when prompted\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
